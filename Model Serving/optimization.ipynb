{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24d66c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NewsRecommendationModel(\n",
       "  (news_encoder): NewsEncoder(\n",
       "    (embedding): Embedding(31638, 100)\n",
       "    (fc1): Linear(in_features=100, out_features=128, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (user_encoder): UserEncoder(\n",
       "    (attention): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=64, out_features=1, bias=True)\n",
       "      (3): Softmax(dim=1)\n",
       "    )\n",
       "  )\n",
       "  (criterion): BCELoss()\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model_train_with_mlflow import NewsRecommendationModel\n",
    "\n",
    "model1 = NewsRecommendationModel.load_from_checkpoint('latest_checkpoint.pth')\n",
    "model1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8262eb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has been successfully converted to ONNX format.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Define dummy input for the model (adjust the size based on your model's input requirements)\n",
    "dummy_input = {\n",
    "    \"news\": torch.randint(0, 31638, (1, 10)),  # Example input for news_encoder\n",
    "    \"user\": torch.randint(0, 31638, (1, 50))   # Example input for user_encoder\n",
    "}\n",
    "\n",
    "# Export the model to ONNX format\n",
    "# Create dummy data based on the model's input requirements\n",
    "batch_history = torch.randint(0, 31638, (1, 50))  # Example input for user history\n",
    "batch_tokens = torch.randint(0, 31638, (1, 10))   # Example input for news tokens\n",
    "\n",
    "# Export the model to ONNX format\n",
    "torch.onnx.export(\n",
    "    model1, \n",
    "    (batch_history, batch_tokens),  # Provide the inputs as a tuple\n",
    "    \"news_recommendation_model.onnx\", \n",
    "    input_names=[\"batch_history\", \"batch_tokens\"], \n",
    "    output_names=[\"output\"], \n",
    "    dynamic_axes={\n",
    "        \"batch_history\": {0: \"batch_size\", 1: \"history_seq_len\"},\n",
    "        \"batch_tokens\": {0: \"batch_size\", 1: \"tokens_seq_len\"},\n",
    "        \"output\": {0: \"batch_size\"}\n",
    "    },\n",
    "    opset_version=11\n",
    ")\n",
    "\n",
    "print(\"Model has been successfully converted to ONNX format.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0be068c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading behaviors and news data...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 376471 entries, 0 to 376470\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   impression_id  376471 non-null  int64 \n",
      " 1   user_id        376471 non-null  object\n",
      " 2   time           376471 non-null  object\n",
      " 3   history        365201 non-null  object\n",
      " 4   impressions    376471 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 14.4+ MB\n",
      "None\n",
      "Extracting news features...\n",
      "Initializing tokenizer...\n",
      "Vocabulary size: 31638\n",
      "Data loading completed successfully.\n",
      "Loading the model...\n",
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from app import load_data\n",
    "model, behaviors_data, news_data, news_features, tokenizer = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22974d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_with_onnx_weights(model, tokenizer, behaviors_data, news_data, news_features, user_id=None, history=None, num_recommendations=5, device='cpu'):\n",
    "    \"\"\"\n",
    "    Test the model with .pth weights on a specific user or with custom history\n",
    "    \n",
    "    Args:\n",
    "        model: Loaded NewsRecommendationModel\n",
    "        tokenizer: Initialized tokenizer\n",
    "        behaviors_data: Loaded behaviors data\n",
    "        news_data: Loaded news data\n",
    "        news_features: Extracted news features\n",
    "        user_id: User ID from the dataset (if None, will use custom history)\n",
    "        history: List of news IDs for custom history (required if user_id is None)\n",
    "        num_recommendations: Number of recommendations to generate\n",
    "        device: Device to run model on ('cpu' or 'cuda')\n",
    "    \n",
    "    Returns:\n",
    "        List of recommended news items\n",
    "    \"\"\"\n",
    "    # If user_id is provided, get their history from the dataset\n",
    "    if user_id is not None:\n",
    "        print(f\"Looking up user {user_id}...\")\n",
    "        dev_behaviors = behaviors_data[\"dev\"]\n",
    "        test_behaviors = behaviors_data[\"test\"]\n",
    "        \n",
    "        # Try to find user in dev or test behaviors\n",
    "        print(dev_behaviors.info()) \n",
    "        user_data = dev_behaviors[dev_behaviors['user_id'] == user_id]\n",
    "        if user_data.empty:\n",
    "            user_data = test_behaviors[test_behaviors['user_id'] == user_id]\n",
    "        \n",
    "        if user_data.empty:\n",
    "            print(f\"User {user_id} not found in dataset\")\n",
    "            return None\n",
    "        \n",
    "        # Get user history\n",
    "        user_history = user_data.iloc[0]['history'].split() if isinstance(user_data.iloc[0]['history'], str) and pd.notna(user_data.iloc[0]['history']) else []\n",
    "        print(f\"Found user with {len(user_history)} items in history\")\n",
    "    else:\n",
    "        # Use provided history\n",
    "        if history is None:\n",
    "            print(\"Error: If user_id is not provided, history must be provided\")\n",
    "            return None\n",
    "        user_history = history\n",
    "        print(f\"Using custom history with {len(history)} items\")\n",
    "    \n",
    "    # Get candidate news IDs (all available news)\n",
    "    candidate_news_ids = list(news_features.keys())\n",
    "    \n",
    "    # To speed up testing, limit the number of candidates\n",
    "    max_candidates = 1000\n",
    "    if len(candidate_news_ids) > max_candidates:\n",
    "        print(f\"Limiting candidates from {len(candidate_news_ids)} to {max_candidates} for faster processing\")\n",
    "        candidate_news_ids = candidate_news_ids[:max_candidates]\n",
    "    else:\n",
    "        print(f\"Using {len(candidate_news_ids)} news items as candidates\")\n",
    "    \n",
    "    print(\"Generating recommendations...\")\n",
    "    \n",
    "    # SELF-CONTAINED RECOMMENDATION FUNCTION\n",
    "    # Process user history\n",
    "    max_history = 20\n",
    "    history = user_history[:max_history]\n",
    "    if len(history) < max_history:\n",
    "        history += ['PAD'] * (max_history - len(history))\n",
    "        \n",
    "    # Process history titles\n",
    "    history_tokens_list = []\n",
    "    for h_news_id in history:\n",
    "        title = news_features.get(h_news_id, {}).get('title', '') if h_news_id != 'PAD' else ''\n",
    "        tokens = tokenizer.tokenize(title)\n",
    "        history_tokens_list.append(tokens)\n",
    "    \n",
    "    history_tokens = torch.stack(history_tokens_list).unsqueeze(0).to(device)  # Add batch dimension\n",
    "    \n",
    "    # Process candidates and get scores\n",
    "    candidate_scores = []\n",
    "    \n",
    "    # Process in batches for efficiency\n",
    "    batch_size = 64\n",
    "    for i in range(0, len(candidate_news_ids), batch_size):\n",
    "        batch_news_ids = candidate_news_ids[i:i+batch_size]\n",
    "        \n",
    "        # Print progress\n",
    "        if i % 200 == 0:\n",
    "            print(f\"Processing candidates {i} to {i+len(batch_news_ids)} of {len(candidate_news_ids)}\")\n",
    "        \n",
    "        batch_tokens_list = []\n",
    "        for news_id in batch_news_ids:\n",
    "            title = news_features.get(news_id, {}).get('title', '')\n",
    "            tokens = tokenizer.tokenize(title)\n",
    "            batch_tokens_list.append(tokens)\n",
    "        \n",
    "        batch_tokens = torch.stack(batch_tokens_list).to(device)\n",
    "        \n",
    "        # We need to broadcast history_tokens to match batch_tokens\n",
    "        batch_history = history_tokens.repeat(len(batch_news_ids), 1, 1).view(len(batch_news_ids), -1)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            try:\n",
    "                # Use ONNX runtime to run the model\n",
    "                import onnxruntime as ort\n",
    "                session = ort.InferenceSession(model.SerializeToString())\n",
    "                \n",
    "                # Prepare inputs for ONNX model\n",
    "                inputs = {\n",
    "                    \"batch_history\": batch_history.cpu().numpy(),\n",
    "                    \"batch_tokens\": batch_tokens.cpu().numpy()\n",
    "                }\n",
    "                \n",
    "                # Run inference\n",
    "                outputs = session.run(None, inputs)\n",
    "                scores = outputs[0]  # Assuming the first output is the scores\n",
    "                \n",
    "                for j, news_id in enumerate(batch_news_ids):\n",
    "                    candidate_scores.append((news_id, scores[j]))\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing batch: {e}\")\n",
    "                continue\n",
    "    \n",
    "    # Sort by score\n",
    "    candidate_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get top recommendations\n",
    "    recommended_news = [news_id for news_id, _ in candidate_scores[:num_recommendations]]\n",
    "    \n",
    "    # Print recommendations\n",
    "    print(f\"\\nTop {num_recommendations} recommendations:\")\n",
    "    actual_recommendations = [\n",
    "        {\"news_id\": news_id, \"title\": news_features.get(news_id, {}).get('title', 'Unknown')}\n",
    "        for news_id in recommended_news\n",
    "    ]\n",
    "    \n",
    "    print(actual_recommendations)\n",
    "    return actual_recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "99b83ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking up user U254959...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 376471 entries, 0 to 376470\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   impression_id  376471 non-null  int64 \n",
      " 1   user_id        376471 non-null  object\n",
      " 2   time           376471 non-null  object\n",
      " 3   history        365201 non-null  object\n",
      " 4   impressions    376471 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 14.4+ MB\n",
      "None\n",
      "Found user with 57 items in history\n",
      "Limiting candidates from 130379 to 1000 for faster processing\n",
      "Generating recommendations...\n",
      "Processing candidates 0 to 64 of 1000\n",
      "\n",
      "Top 5 recommendations:\n",
      "[{'news_id': 'N67526', 'title': 'Star Tracks: Celebs on Vacation'}, {'news_id': 'N86440', 'title': \"Stowaway Discovered in Couple's Carry-On Luggage\"}, {'news_id': 'N110516', 'title': \"16 Live-Action Disney Movies in the Works After 'Maleficent: Mistress of Evil' (Photos)\"}, {'news_id': 'N94988', 'title': 'Latest Automotive Safety Recalls'}, {'news_id': 'N113706', 'title': 'Cooking advice you should never believe'}]\n",
      "Looking up user U254959...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 376471 entries, 0 to 376470\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   impression_id  376471 non-null  int64 \n",
      " 1   user_id        376471 non-null  object\n",
      " 2   time           376471 non-null  object\n",
      " 3   history        365201 non-null  object\n",
      " 4   impressions    376471 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 14.4+ MB\n",
      "None\n",
      "Found user with 57 items in history\n",
      "Limiting candidates from 130379 to 1000 for faster processing\n",
      "Generating recommendations...\n",
      "Processing candidates 0 to 64 of 1000\n",
      "\n",
      "Top 5 recommendations:\n",
      "[{'news_id': 'N67526', 'title': 'Star Tracks: Celebs on Vacation'}, {'news_id': 'N86440', 'title': \"Stowaway Discovered in Couple's Carry-On Luggage\"}, {'news_id': 'N110516', 'title': \"16 Live-Action Disney Movies in the Works After 'Maleficent: Mistress of Evil' (Photos)\"}, {'news_id': 'N94988', 'title': 'Latest Automotive Safety Recalls'}, {'news_id': 'N113706', 'title': 'Cooking advice you should never believe'}]\n",
      "Looking up user U254959...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 376471 entries, 0 to 376470\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   impression_id  376471 non-null  int64 \n",
      " 1   user_id        376471 non-null  object\n",
      " 2   time           376471 non-null  object\n",
      " 3   history        365201 non-null  object\n",
      " 4   impressions    376471 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 14.4+ MB\n",
      "None\n",
      "Found user with 57 items in history\n",
      "Limiting candidates from 130379 to 1000 for faster processing\n",
      "Generating recommendations...\n",
      "Processing candidates 0 to 64 of 1000\n",
      "\n",
      "Top 5 recommendations:\n",
      "[{'news_id': 'N67526', 'title': 'Star Tracks: Celebs on Vacation'}, {'news_id': 'N86440', 'title': \"Stowaway Discovered in Couple's Carry-On Luggage\"}, {'news_id': 'N110516', 'title': \"16 Live-Action Disney Movies in the Works After 'Maleficent: Mistress of Evil' (Photos)\"}, {'news_id': 'N94988', 'title': 'Latest Automotive Safety Recalls'}, {'news_id': 'N113706', 'title': 'Cooking advice you should never believe'}]\n",
      "Looking up user U254959...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 376471 entries, 0 to 376470\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   impression_id  376471 non-null  int64 \n",
      " 1   user_id        376471 non-null  object\n",
      " 2   time           376471 non-null  object\n",
      " 3   history        365201 non-null  object\n",
      " 4   impressions    376471 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 14.4+ MB\n",
      "None\n",
      "Found user with 57 items in history\n",
      "Limiting candidates from 130379 to 1000 for faster processing\n",
      "Generating recommendations...\n",
      "Processing candidates 0 to 64 of 1000\n",
      "\n",
      "Top 5 recommendations:\n",
      "[{'news_id': 'N67526', 'title': 'Star Tracks: Celebs on Vacation'}, {'news_id': 'N86440', 'title': \"Stowaway Discovered in Couple's Carry-On Luggage\"}, {'news_id': 'N110516', 'title': \"16 Live-Action Disney Movies in the Works After 'Maleficent: Mistress of Evil' (Photos)\"}, {'news_id': 'N94988', 'title': 'Latest Automotive Safety Recalls'}, {'news_id': 'N113706', 'title': 'Cooking advice you should never believe'}]\n",
      "Looking up user U254959...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 376471 entries, 0 to 376470\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   impression_id  376471 non-null  int64 \n",
      " 1   user_id        376471 non-null  object\n",
      " 2   time           376471 non-null  object\n",
      " 3   history        365201 non-null  object\n",
      " 4   impressions    376471 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 14.4+ MB\n",
      "None\n",
      "Found user with 57 items in history\n",
      "Limiting candidates from 130379 to 1000 for faster processing\n",
      "Generating recommendations...\n",
      "Processing candidates 0 to 64 of 1000\n",
      "\n",
      "Top 5 recommendations:\n",
      "[{'news_id': 'N67526', 'title': 'Star Tracks: Celebs on Vacation'}, {'news_id': 'N86440', 'title': \"Stowaway Discovered in Couple's Carry-On Luggage\"}, {'news_id': 'N110516', 'title': \"16 Live-Action Disney Movies in the Works After 'Maleficent: Mistress of Evil' (Photos)\"}, {'news_id': 'N94988', 'title': 'Latest Automotive Safety Recalls'}, {'news_id': 'N113706', 'title': 'Cooking advice you should never believe'}]\n",
      "Looking up user U254959...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 376471 entries, 0 to 376470\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   impression_id  376471 non-null  int64 \n",
      " 1   user_id        376471 non-null  object\n",
      " 2   time           376471 non-null  object\n",
      " 3   history        365201 non-null  object\n",
      " 4   impressions    376471 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 14.4+ MB\n",
      "None\n",
      "Found user with 57 items in history\n",
      "Limiting candidates from 130379 to 1000 for faster processing\n",
      "Generating recommendations...\n",
      "Processing candidates 0 to 64 of 1000\n",
      "\n",
      "Top 5 recommendations:\n",
      "[{'news_id': 'N67526', 'title': 'Star Tracks: Celebs on Vacation'}, {'news_id': 'N86440', 'title': \"Stowaway Discovered in Couple's Carry-On Luggage\"}, {'news_id': 'N110516', 'title': \"16 Live-Action Disney Movies in the Works After 'Maleficent: Mistress of Evil' (Photos)\"}, {'news_id': 'N94988', 'title': 'Latest Automotive Safety Recalls'}, {'news_id': 'N113706', 'title': 'Cooking advice you should never believe'}]\n",
      "Looking up user U254959...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 376471 entries, 0 to 376470\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   impression_id  376471 non-null  int64 \n",
      " 1   user_id        376471 non-null  object\n",
      " 2   time           376471 non-null  object\n",
      " 3   history        365201 non-null  object\n",
      " 4   impressions    376471 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 14.4+ MB\n",
      "None\n",
      "Found user with 57 items in history\n",
      "Limiting candidates from 130379 to 1000 for faster processing\n",
      "Generating recommendations...\n",
      "Processing candidates 0 to 64 of 1000\n",
      "\n",
      "Top 5 recommendations:\n",
      "[{'news_id': 'N67526', 'title': 'Star Tracks: Celebs on Vacation'}, {'news_id': 'N86440', 'title': \"Stowaway Discovered in Couple's Carry-On Luggage\"}, {'news_id': 'N110516', 'title': \"16 Live-Action Disney Movies in the Works After 'Maleficent: Mistress of Evil' (Photos)\"}, {'news_id': 'N94988', 'title': 'Latest Automotive Safety Recalls'}, {'news_id': 'N113706', 'title': 'Cooking advice you should never believe'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'news_id': 'N67526', 'title': 'Star Tracks: Celebs on Vacation'},\n",
       " {'news_id': 'N86440',\n",
       "  'title': \"Stowaway Discovered in Couple's Carry-On Luggage\"},\n",
       " {'news_id': 'N110516',\n",
       "  'title': \"16 Live-Action Disney Movies in the Works After 'Maleficent: Mistress of Evil' (Photos)\"},\n",
       " {'news_id': 'N94988', 'title': 'Latest Automotive Safety Recalls'},\n",
       " {'news_id': 'N113706', 'title': 'Cooking advice you should never believe'}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from app import test_model_with_pth_weights\n",
    "import pandas as pd\n",
    "\n",
    "test_model_with_onnx_weights(onnx_model, tokenizer, behaviors_data, news_data, news_features, user_id='U254959')\n",
    "test_model_with_onnx_weights(onnx_model, tokenizer, behaviors_data, news_data, news_features, user_id='U254959')\n",
    "\n",
    "test_model_with_onnx_weights(onnx_model, tokenizer, behaviors_data, news_data, news_features, user_id='U254959')\n",
    "\n",
    "test_model_with_onnx_weights(onnx_model, tokenizer, behaviors_data, news_data, news_features, user_id='U254959')\n",
    "test_model_with_onnx_weights(onnx_model, tokenizer, behaviors_data, news_data, news_features, user_id='U254959')\n",
    "test_model_with_onnx_weights(onnx_model, tokenizer, behaviors_data, news_data, news_features, user_id='U254959')\n",
    "\n",
    "test_model_with_onnx_weights(onnx_model, tokenizer, behaviors_data, news_data, news_features, user_id='U254959')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7bcdbc37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking up user U254959...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 376471 entries, 0 to 376470\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   impression_id  376471 non-null  int64 \n",
      " 1   user_id        376471 non-null  object\n",
      " 2   time           376471 non-null  object\n",
      " 3   history        365201 non-null  object\n",
      " 4   impressions    376471 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 14.4+ MB\n",
      "None\n",
      "Found user with 57 items in history\n",
      "Limiting candidates from 130379 to 1000 for faster processing\n",
      "Generating recommendations...\n",
      "Processing candidates 0 to 64 of 1000\n",
      "\n",
      "Top 5 recommendations:\n",
      "[{'news_id': 'N67526', 'title': 'Star Tracks: Celebs on Vacation'}, {'news_id': 'N86440', 'title': \"Stowaway Discovered in Couple's Carry-On Luggage\"}, {'news_id': 'N110516', 'title': \"16 Live-Action Disney Movies in the Works After 'Maleficent: Mistress of Evil' (Photos)\"}, {'news_id': 'N94988', 'title': 'Latest Automotive Safety Recalls'}, {'news_id': 'N113706', 'title': 'Cooking advice you should never believe'}]\n",
      "Looking up user U254959...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 376471 entries, 0 to 376470\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   impression_id  376471 non-null  int64 \n",
      " 1   user_id        376471 non-null  object\n",
      " 2   time           376471 non-null  object\n",
      " 3   history        365201 non-null  object\n",
      " 4   impressions    376471 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 14.4+ MB\n",
      "None\n",
      "Found user with 57 items in history\n",
      "Limiting candidates from 130379 to 1000 for faster processing\n",
      "Generating recommendations...\n",
      "Processing candidates 0 to 64 of 1000\n",
      "\n",
      "Top 5 recommendations:\n",
      "[{'news_id': 'N67526', 'title': 'Star Tracks: Celebs on Vacation'}, {'news_id': 'N86440', 'title': \"Stowaway Discovered in Couple's Carry-On Luggage\"}, {'news_id': 'N110516', 'title': \"16 Live-Action Disney Movies in the Works After 'Maleficent: Mistress of Evil' (Photos)\"}, {'news_id': 'N94988', 'title': 'Latest Automotive Safety Recalls'}, {'news_id': 'N113706', 'title': 'Cooking advice you should never believe'}]\n",
      "Looking up user U254959...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 376471 entries, 0 to 376470\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   impression_id  376471 non-null  int64 \n",
      " 1   user_id        376471 non-null  object\n",
      " 2   time           376471 non-null  object\n",
      " 3   history        365201 non-null  object\n",
      " 4   impressions    376471 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 14.4+ MB\n",
      "None\n",
      "Found user with 57 items in history\n",
      "Limiting candidates from 130379 to 1000 for faster processing\n",
      "Generating recommendations...\n",
      "Processing candidates 0 to 64 of 1000\n",
      "\n",
      "Top 5 recommendations:\n",
      "[{'news_id': 'N67526', 'title': 'Star Tracks: Celebs on Vacation'}, {'news_id': 'N86440', 'title': \"Stowaway Discovered in Couple's Carry-On Luggage\"}, {'news_id': 'N110516', 'title': \"16 Live-Action Disney Movies in the Works After 'Maleficent: Mistress of Evil' (Photos)\"}, {'news_id': 'N94988', 'title': 'Latest Automotive Safety Recalls'}, {'news_id': 'N113706', 'title': 'Cooking advice you should never believe'}]\n",
      "Looking up user U254959...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 376471 entries, 0 to 376470\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   impression_id  376471 non-null  int64 \n",
      " 1   user_id        376471 non-null  object\n",
      " 2   time           376471 non-null  object\n",
      " 3   history        365201 non-null  object\n",
      " 4   impressions    376471 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 14.4+ MB\n",
      "None\n",
      "Found user with 57 items in history\n",
      "Limiting candidates from 130379 to 1000 for faster processing\n",
      "Generating recommendations...\n",
      "Processing candidates 0 to 64 of 1000\n",
      "\n",
      "Top 5 recommendations:\n",
      "[{'news_id': 'N67526', 'title': 'Star Tracks: Celebs on Vacation'}, {'news_id': 'N86440', 'title': \"Stowaway Discovered in Couple's Carry-On Luggage\"}, {'news_id': 'N110516', 'title': \"16 Live-Action Disney Movies in the Works After 'Maleficent: Mistress of Evil' (Photos)\"}, {'news_id': 'N94988', 'title': 'Latest Automotive Safety Recalls'}, {'news_id': 'N113706', 'title': 'Cooking advice you should never believe'}]\n",
      "Looking up user U254959...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 376471 entries, 0 to 376470\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   impression_id  376471 non-null  int64 \n",
      " 1   user_id        376471 non-null  object\n",
      " 2   time           376471 non-null  object\n",
      " 3   history        365201 non-null  object\n",
      " 4   impressions    376471 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 14.4+ MB\n",
      "None\n",
      "Found user with 57 items in history\n",
      "Limiting candidates from 130379 to 1000 for faster processing\n",
      "Generating recommendations...\n",
      "Processing candidates 0 to 64 of 1000\n",
      "\n",
      "Top 5 recommendations:\n",
      "[{'news_id': 'N67526', 'title': 'Star Tracks: Celebs on Vacation'}, {'news_id': 'N86440', 'title': \"Stowaway Discovered in Couple's Carry-On Luggage\"}, {'news_id': 'N110516', 'title': \"16 Live-Action Disney Movies in the Works After 'Maleficent: Mistress of Evil' (Photos)\"}, {'news_id': 'N94988', 'title': 'Latest Automotive Safety Recalls'}, {'news_id': 'N113706', 'title': 'Cooking advice you should never believe'}]\n",
      "Looking up user U254959...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 376471 entries, 0 to 376470\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   impression_id  376471 non-null  int64 \n",
      " 1   user_id        376471 non-null  object\n",
      " 2   time           376471 non-null  object\n",
      " 3   history        365201 non-null  object\n",
      " 4   impressions    376471 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 14.4+ MB\n",
      "None\n",
      "Found user with 57 items in history\n",
      "Limiting candidates from 130379 to 1000 for faster processing\n",
      "Generating recommendations...\n",
      "Processing candidates 0 to 64 of 1000\n",
      "\n",
      "Top 5 recommendations:\n",
      "[{'news_id': 'N67526', 'title': 'Star Tracks: Celebs on Vacation'}, {'news_id': 'N86440', 'title': \"Stowaway Discovered in Couple's Carry-On Luggage\"}, {'news_id': 'N110516', 'title': \"16 Live-Action Disney Movies in the Works After 'Maleficent: Mistress of Evil' (Photos)\"}, {'news_id': 'N94988', 'title': 'Latest Automotive Safety Recalls'}, {'news_id': 'N113706', 'title': 'Cooking advice you should never believe'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'news_id': 'N67526', 'title': 'Star Tracks: Celebs on Vacation'},\n",
       " {'news_id': 'N86440',\n",
       "  'title': \"Stowaway Discovered in Couple's Carry-On Luggage\"},\n",
       " {'news_id': 'N110516',\n",
       "  'title': \"16 Live-Action Disney Movies in the Works After 'Maleficent: Mistress of Evil' (Photos)\"},\n",
       " {'news_id': 'N94988', 'title': 'Latest Automotive Safety Recalls'},\n",
       " {'news_id': 'N113706', 'title': 'Cooking advice you should never believe'}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model_with_pth_weights(model, tokenizer, behaviors_data, news_data, news_features, user_id='U254959')\n",
    "test_model_with_pth_weights(model, tokenizer, behaviors_data, news_data, news_features, user_id='U254959')\n",
    "test_model_with_pth_weights(model, tokenizer, behaviors_data, news_data, news_features, user_id='U254959')\n",
    "test_model_with_pth_weights(model, tokenizer, behaviors_data, news_data, news_features, user_id='U254959')\n",
    "test_model_with_pth_weights(model, tokenizer, behaviors_data, news_data, news_features, user_id='U254959')\n",
    "test_model_with_pth_weights(model, tokenizer, behaviors_data, news_data, news_features, user_id='U254959')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e76bfd33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method _DeviceDtypeModuleMixin.type of NewsRecommendationModel(\n",
       "  (news_encoder): NewsEncoder(\n",
       "    (embedding): Embedding(31638, 100)\n",
       "    (fc1): Linear(in_features=100, out_features=128, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (user_encoder): UserEncoder(\n",
       "    (attention): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=64, out_features=1, bias=True)\n",
       "      (3): Softmax(dim=1)\n",
       "    )\n",
       "  )\n",
       "  (criterion): BCELoss()\n",
       ")>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "135614cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnxruntime as ort\n",
    "\n",
    "# Load the ONNX model\n",
    "onnx_model = onnx.load(\"news_recommendation_model.onnx\")\n",
    "onnx.checker.check_model(onnx_model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c1eebd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnxruntime\n",
      "  Downloading onnxruntime-1.21.1-cp311-cp311-win_amd64.whl (12.3 MB)\n",
      "     --------------------------------------- 12.3/12.3 MB 32.8 MB/s eta 0:00:00\n",
      "Collecting coloredlogs\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "     ---------------------------------------- 46.0/46.0 kB ? eta 0:00:00\n",
      "Collecting flatbuffers\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Requirement already satisfied: numpy>=1.21.6 in c:\\users\\alexm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from onnxruntime) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\alexm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from onnxruntime) (24.2)\n",
      "Requirement already satisfied: protobuf in c:\\users\\alexm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from onnxruntime) (5.29.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\alexm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from onnxruntime) (1.13.1)\n",
      "Collecting humanfriendly>=9.1\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "     ---------------------------------------- 86.8/86.8 kB ? eta 0:00:00\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\alexm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->onnxruntime) (1.3.0)\n",
      "Collecting pyreadline3\n",
      "  Downloading pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
      "     ---------------------------------------- 83.2/83.2 kB 4.9 MB/s eta 0:00:00\n",
      "Installing collected packages: flatbuffers, pyreadline3, humanfriendly, coloredlogs, onnxruntime\n",
      "Successfully installed coloredlogs-15.0.1 flatbuffers-25.2.10 humanfriendly-10.0 onnxruntime-1.21.1 pyreadline3-3.5.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac9573c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import onnxruntime as ort\n",
    "\n",
    "def test_model_with_onnx_weights(\n",
    "    model, tokenizer, behaviors_data, news_data, news_features,\n",
    "    user_id=None, history=None, num_recommendations=5, device='cpu'\n",
    "):\n",
    "    \"\"\"\n",
    "    Test the model with ONNX weights using either a user ID or custom history.\n",
    "    \"\"\"\n",
    "    # 1. Get user history\n",
    "    if user_id:\n",
    "        print(f\"Looking up user {user_id}...\")\n",
    "        dev_behaviors = behaviors_data[\"dev\"]\n",
    "        test_behaviors = behaviors_data[\"test\"]\n",
    "\n",
    "        user_data = dev_behaviors[dev_behaviors['user_id'] == user_id]\n",
    "        if user_data.empty:\n",
    "            user_data = test_behaviors[test_behaviors['user_id'] == user_id]\n",
    "\n",
    "        if user_data.empty:\n",
    "            print(f\"User {user_id} not found.\")\n",
    "            return None\n",
    "\n",
    "        user_history = user_data.iloc[0]['history']\n",
    "        user_history = user_history.split() if pd.notna(user_history) else []\n",
    "    else:\n",
    "        if not history:\n",
    "            print(\"Error: Provide either a user_id or history.\")\n",
    "            return None\n",
    "        user_history = history\n",
    "\n",
    "    print(f\"Using history with {len(user_history)} items\")\n",
    "\n",
    "    # 2. Trim/pad history\n",
    "    max_history = 20\n",
    "    history_ids = user_history[:max_history] + ['PAD'] * (max_history - len(user_history))\n",
    "\n",
    "    history_titles = [\n",
    "        news_features.get(nid, {}).get('title', '') if nid != 'PAD' else ''\n",
    "        for nid in history_ids\n",
    "    ]\n",
    "    history_tokens = torch.stack([tokenizer.tokenize(title) for title in history_titles])\n",
    "    history_tokens = history_tokens.unsqueeze(0).to(device)  # [1, 20, embedding_dim]\n",
    "\n",
    "    # 3. Prepare candidate news\n",
    "    candidate_news_ids = list(news_features.keys())\n",
    "    max_candidates = 1000\n",
    "    if len(candidate_news_ids) > max_candidates:\n",
    "        print(f\"Limiting candidates to {max_candidates}\")\n",
    "        candidate_news_ids = candidate_news_ids[:max_candidates]\n",
    "\n",
    "    # 4. Initialize ONNX session\n",
    "    try:\n",
    "        session = ort.InferenceSession(model.SerializeToString())\n",
    "    except Exception as e:\n",
    "        print(f\"ONNX Session error: {e}\")\n",
    "        return None\n",
    "\n",
    "    candidate_scores = []\n",
    "    batch_size = 64\n",
    "\n",
    "    # 5. Batch process candidate news\n",
    "    for i in range(0, len(candidate_news_ids), batch_size):\n",
    "        batch_news_ids = candidate_news_ids[i:i+batch_size]\n",
    "        print(f\"Processing candidates {i}–{i+len(batch_news_ids)}\")\n",
    "\n",
    "        batch_titles = [news_features.get(nid, {}).get('title', '') for nid in batch_news_ids]\n",
    "        batch_tokens = torch.stack([tokenizer.tokenize(title) for title in batch_titles]).to(device)\n",
    "\n",
    "        # Repeat history for the batch\n",
    "        batch_history = history_tokens.repeat(len(batch_news_ids), 1, 1).view(len(batch_news_ids), -1)\n",
    "\n",
    "        # ONNX inference\n",
    "        try:\n",
    "            inputs = {\n",
    "                \"batch_history\": batch_history.cpu().numpy(),\n",
    "                \"batch_tokens\": batch_tokens.cpu().numpy()\n",
    "            }\n",
    "            outputs = session.run(None, inputs)\n",
    "            scores = outputs[0]\n",
    "\n",
    "            candidate_scores.extend(zip(batch_news_ids, scores))\n",
    "        except Exception as e:\n",
    "            print(f\"Batch error: {e}\")\n",
    "            continue\n",
    "\n",
    "    # 6. Select top recommendations\n",
    "    top_candidates = sorted(candidate_scores, key=lambda x: x[1], reverse=True)[:num_recommendations]\n",
    "\n",
    "    recommendations = [\n",
    "        {\"news_id\": nid, \"title\": news_features.get(nid, {}).get('title', 'Unknown')}\n",
    "        for nid, _ in top_candidates\n",
    "    ]\n",
    "\n",
    "    print(f\"\\nTop {num_recommendations} recommendations:\")\n",
    "    for rec in recommendations:\n",
    "        print(rec)\n",
    "\n",
    "    return recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0eb1786",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
